{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e563602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c2fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"claudeAPI\")\n",
    "groqAPI = os.getenv(\"groqAPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28750c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "claude = ChatAnthropic(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    temperature = 0.7,\n",
    "    api_key = api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8b22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "groq = ChatGroq(\n",
    "    model = \"qwen/qwen3-32b\",\n",
    "    api_key = groqAPI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafd8823",
   "metadata": {},
   "source": [
    "#### How to use Chat Messages as our Graph State\n",
    "Messages = Human, AI, System and ToolMessage\n",
    "\n",
    "- Every Message have these important \n",
    "  - Content\n",
    "  - Name \n",
    "  - Response_metadata - optionally, a dict of metadata (Eg : Often  populated by model provider for AIMessages)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2876b32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Please tell how can I help\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Akash\n",
      "\n",
      "I am learning LangGraph Applications\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "What specifically you want to learn about LangGraph\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages = [AIMessage(content= f\"Please tell how can I help\", name = \"LLMModel\")]\n",
    "messages.append(HumanMessage(content = f\"I am learning LangGraph Applications\", name = \"Akash\"))\n",
    "messages.append(AIMessage(content = f\"What specifically you want to learn about LangGraph\")) \n",
    "\n",
    "\n",
    "for message in messages :\n",
    "    message.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85257dcd",
   "metadata": {},
   "source": [
    "- Inside the Graph State, we will append all the messages \n",
    "- Appending of the messages will be done using Reducers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2007b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call using groq LLM\n",
    "result = groq.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad7533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, the user is learning LangGraph applications. Let me see what they might need help with. They previously asked for help, and I responded by asking for specifics. Now they\\'re back with an empty message. Maybe they\\'re unsure where to start.\\n\\nFirst, LangGraph is a framework for building stateful, graph-based workflows with LLMs. So I should outline key areas. Maybe start with basic concepts like nodes, edges, and states. Then move to practical steps: setting up the environment, writing their first app, handling states, and using memory.\\n\\nThey might want to know how to structure a workflow. For example, a simple Q&A app with a retriever node and a response node. Including code examples would help. Also, mention advanced topics like dynamic graph structures or integrating with other tools.\\n\\nWait, the user might not have a clear direction. Should I list common use cases? Like customer support chatbots or data analysis pipelines. That could give them ideas. Also, resources like the official documentation or community forums might be useful.\\n\\nI should ask if they have a specific project in mind or need guidance on a particular aspect. That way, I can tailor the response. Maybe break it down into sections with examples and then offer further assistance based on their needs.\\n</think>\\n\\nIf you\\'re learning **LangGraph** (a framework for building stateful, graph-based applications with language models), here\\'s a structured approach to help you get started and deepen your understanding:\\n\\n---\\n\\n### **1. Core Concepts to Master**\\n- **Graph Structure**: Learn how to define **nodes** (tasks/steps) and **edges** (connections between nodes) to create workflows.\\n- **State Management**: Understand how to manage and pass **state** (data) between nodes using `GraphState` or similar constructs.\\n- **LLM Integration**: Use LangGraph to chain LLM calls (e.g., with `Runnable` classes) into your graph.\\n- **Memory & Tools**: Explore tools for persisting memory (e.g., `Memory` class) or integrating external APIs/Retrievers.\\n\\n---\\n\\n### **2. Practical Steps to Build a LangGraph App**\\n1. **Install Dependencies**:\\n   ```bash\\n   pip install langgraph langchain\\n   ```\\n\\n2. **Basic Example**:\\n   ```python\\n   from langgraph.graph import Graph\\n   from langchain_core.runnables import RunnableLambda\\n\\n   # Define nodes as functions or Runnables\\n   def node1(state):\\n       return {\"output\": \"Hello from Node 1!\"}\\n\\n   def node2(state):\\n       return {\"output\": f\"{state[\\'output\\']} + Hello from Node 2!\"}\\n\\n   # Build the graph\\n   graph = Graph()\\n   graph.add_node(\"node1\", RunnableLambda(node1))\\n   graph.add_node(\"node2\", RunnableLambda(node2))\\n   graph.add_edge(\"node1\", \"node2\")  # node1 â†’ node2\\n   graph.set_entry_point(\"node1\")\\n   graph.set_finish_point(\"node2\")\\n\\n   # Run the graph\\n   result = graph.invoke({\"input\": \"Start\"})\\n   print(result)  # Output: {\"output\": \"Hello from Node 1! + Hello from Node 2!\"}\\n   ```\\n\\n3. **Advanced Use Cases**:\\n   - **Dynamic Graphs**: Use conditional logic (e.g., `@graph.add_conditional_edges`) to route to different nodes.\\n   - **LLM-Driven Steps**: Integrate an LLM into a node:\\n     ```python\\n     from langchain_openai import OpenAI\\n\\n     llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\\n     graph.add_node(\"llm_node\", llm)\\n     ```\\n\\n---\\n\\n### **3. Common Applications**\\n- **Customer Support Chatbot**: Route user queries to the right department (e.g., billing, technical support).\\n- **Data Analysis Pipeline**: Retrieve data â†’ Clean it â†’ Run analysis â†’ Generate a report.\\n- **Interactive Story Generator**: Use user input to dynamically change story paths (e.g., \"Choose Your Adventure\").\\n\\n---\\n\\n### **4. Resources to Learn More**\\n- **Official Documentation**: [https://langgraph.streamlit.app/](https://langgraph.streamlit.app/)\\n- **LangChain Integration**: Learn how to combine LangGraph with LangChain tools like `Retrievers` or `Agents`.\\n- **Community Examples**: Check out GitHub repositories or the LangChain blog for case studies.\\n\\n---\\n\\n### **5. Troubleshooting Tips**\\n- If your graph isn\\'t executing as expected:\\n  - Print the `state` at each node to debug.\\n  - Ensure all edges are properly defined.\\n  - Validate input/output types between nodes.\\n\\n---\\n\\n**What would you like to focus on next?**  \\n- A specific use case (e.g., building a RAG chatbot)?\\n- Debugging a graph?\\n- Integrating with tools like `TavilySearch` or `SQLDatabase`?\\n- Advanced features like memory or dynamic routing?  \\n\\nLet me know! ðŸ˜Š' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 1045, 'prompt_tokens': 49, 'total_tokens': 1094, 'completion_time': 2.418648922, 'completion_tokens_details': None, 'prompt_time': 0.002066591, 'prompt_tokens_details': None, 'queue_time': 0.070289746, 'total_time': 2.420715513}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019b82cc-5225-7cf0-ab15-d195a4e3dcbf-0' usage_metadata={'input_tokens': 49, 'output_tokens': 1045, 'total_tokens': 1094}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b752b293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 1045,\n",
       "  'prompt_tokens': 49,\n",
       "  'total_tokens': 1094,\n",
       "  'completion_time': 2.418648922,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_time': 0.002066591,\n",
       "  'prompt_tokens_details': None,\n",
       "  'queue_time': 0.070289746,\n",
       "  'total_time': 2.420715513},\n",
       " 'model_name': 'qwen/qwen3-32b',\n",
       " 'system_fingerprint': 'fp_d58dbe76cd',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None,\n",
       " 'model_provider': 'groq'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b30a84",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "- They can be integrated with LLM models to interact with External Systems. External Systems can be API's\n",
    "- Whenever a query is asked the model can choose to call the tool and this query is based on the natural language input and this will return an output that matches the tool schema\n",
    "\n",
    "\n",
    "--> We provide conditional Edge to call a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0052c0cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c059631",
   "metadata": {},
   "source": [
    "How Nodes can be converted to an Agent : Router\n",
    "\n",
    "Router : ChatModel routes b/w a direct response or a tool call based upon the user input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f680d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
