{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f1cf367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"claudeAPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e375ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(\n",
    "    model  = \"claude-haiku-4-5-20251001\",\n",
    "    temperature = 0.7,\n",
    "    api_key= api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3793695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='# AgenticAI: A Comprehensive Overview\\n\\nI don\\'t have specific information about a product or framework called \"AgenticAI\" in my training data. However, I can explain what **agentic AI** refers to and help clarify what you might be looking for.\\n\\n## What is Agentic AI?\\n\\n**Agentic AI** describes AI systems that operate with agency—the ability to:\\n- Set their own goals\\n- Make autonomous decisions\\n- Take actions toward objectives\\n- Adapt based on outcomes\\n- Plan multi-step solutions\\n\\n### Key Characteristics:\\n- **Autonomy**: Operates independently with minimal human intervention\\n- **Goal-orientation**: Works toward defined objectives\\n- **Reasoning**: Uses planning and logic to solve problems\\n- **Tool use**: Leverages APIs, databases, or other resources\\n- **Iteration**: Learns and adjusts from results\\n\\n## Common Examples:\\n- AI research assistants that browse and synthesize information\\n- Autonomous trading systems\\n- Robotic process automation\\n- AI coding assistants that debug and refactor code\\n\\n## Are You Looking For:\\n\\n1. **A specific product/platform** called AgenticAI?\\n2. **General guidance** on building agentic systems?\\n3. **Frameworks** like LangChain, AutoGPT, or similar?\\n\\nCould you provide more context about what you\\'re trying to learn? That way I can give you more targeted information.', additional_kwargs={}, response_metadata={'id': 'msg_01YUL6GmKQweLeurpENntgUT', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 15, 'output_tokens': 320, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'}, id='lc_run--019b6143-ac80-78f1-ad20-e2a361f0d97e-0', usage_metadata={'input_tokens': 15, 'output_tokens': 320, 'total_tokens': 335, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Teach me about AgenticAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad8cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool # it will use a decorator\n",
    "\n",
    "@tool\n",
    "def get_weather(location : str) -> str :\n",
    "    \"\"\" Get the weather at a location \"\"\"\n",
    "    return f\"It's sunny in {location}\"\n",
    "\n",
    "\n",
    "# Bind the tool with the llm\n",
    "model_with_tools = llm.bind_tools([get_weather])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bd88a",
   "metadata": {},
   "source": [
    "bind_tools  : For chat models - gives model awareness of tools but you handle the logic\n",
    "\n",
    "create_agent() : Create a full agent that automatically decides when to use tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec30f2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=[{'id': 'toolu_01Whd8DE46PVNy1zwLXyFgx2', 'input': {'location': 'Boston'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01DDoQMVqAveZPFpoQaqQBgS', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 565, 'output_tokens': 54, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'}, id='lc_run--019b61bc-c171-7f21-b9ae-fad7b9f50ccf-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'toolu_01Whd8DE46PVNy1zwLXyFgx2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 565, 'output_tokens': 54, 'total_tokens': 619, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model_with_tools.invoke(\"what's the weather like in Boston?\")\n",
    "response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a821dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool : get_weather\n",
      "Args : {'location': 'Boston'}\n"
     ]
    }
   ],
   "source": [
    "for tool_call in response.tool_calls :\n",
    "    print(f\"Tool : {tool_call['name']}\")\n",
    "    print(f\"Args : {tool_call['args']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5133c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The weather in Boston is sunny! ☀️' additional_kwargs={} response_metadata={'id': 'msg_01EGsBccTCxGHzQqUxgCxvHq', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 635, 'output_tokens': 14, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'} id='lc_run--019b61c9-e7da-75c0-ba35-bca2ae6e5fb5-0' usage_metadata={'input_tokens': 635, 'output_tokens': 14, 'total_tokens': 649, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}\n"
     ]
    }
   ],
   "source": [
    "# step 1 : model generates tool call\n",
    "messages = [{\"role\" : \"user\", \"content\" : \"What's the weather in Boston?\"}]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "\n",
    "# step 2 : Execute tools and collect results\n",
    "for tool_calls in ai_msg.tool_calls :\n",
    "    tool_result = get_weather.invoke(tool_calls)\n",
    "    messages.append(tool_result)\n",
    "\n",
    "\n",
    "# step 3 : Pass results back to model for the final result\n",
    "final_response = model_with_tools.invoke(messages)\n",
    "print(final_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0e1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2166ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
