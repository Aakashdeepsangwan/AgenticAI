{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6faa9535",
   "metadata": {},
   "source": [
    "### Chain of Thought with RAG\n",
    "\n",
    "Chain of Thoughts (CoT) in RAG ?\n",
    "CoT reasoning breaks down a complex  question into intermediate steps and allow retrieval + reflection at each step before answering\n",
    "\n",
    "- Step 1 : Decompose question -> Sub-steps(Reason)\n",
    "- Step 2 : Retrieve docs per step (Act)\n",
    "- Step 3 : Combine Context (Observe)\n",
    "- Step 4 : Final Answer Generation (Reflect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS \n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7357c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare VectoreStore\n",
    "# .load() makes it a document\n",
    "docs = TextLoader(\"Research_notes.txt\", encoding = \"utf-8\").load()\n",
    "chunks  = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap=50).split_documents(docs)\n",
    "Embeddings = HuggingFaceEmbeddings(\n",
    "    model_name  = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "vs = FAISS.from_documents(chunks, Embeddings)\n",
    "retriever = vs.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ae7ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key  = os.getenv(\"claudeAPI\")\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    temperature = 0.7,\n",
    "    api_key = api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27f9d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "# List it's not a data, it's just used for Data Annotation. As in python variable are Dynamic, using pydantic we make Static\n",
    "class RAGCoTAgent(BaseModel) :\n",
    "    question : str\n",
    "    sub_steps : List[str] = []\n",
    "    retrieved_docs : List[Document] = []\n",
    "    ans : str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade52cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3 Nodes\n",
    "def plan_steps(state : RAGCoTAgent) -> RAGCoTAgent:\n",
    "    prompt = \"\"\" \n",
    "     Break the question into 2-3 reasoning steps : \\n\\n {state.question}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt).content\n",
    "    subqs = [line.strip(\"- \") for line in result.split(\"\\n\") if line.strip()]\n",
    "    return state.model_copy(update = {\"sub_steps\" : subqs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bc057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5399f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
